{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ff37b3-0939-4933-a7be-89983eede386",
   "metadata": {},
   "source": [
    "# 1 DataLoader与Dataset\n",
    "## 1.1 实例：人民币分类\n",
    "\n",
    "\n",
    "$数据\\begin{cases}\n",
    "数据收集 \\rightarrow Img, Label\\\\\n",
    "数据划分 \\rightarrow train, valid, test\\\\\n",
    "数据读取 \\rightarrow DataLoader \\begin{cases}\n",
    "    Sampler \\rightarrow 生成Index\\\\\n",
    "    DataSet \\rightarrow 根据索引读取Img,Label\n",
    "    \\end{cases}\\\\\n",
    "数据预处理 \\rightarrow transforms\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403937e-6127-4e28-9b4c-84484137ea1a",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "### - otrch.utils.data.DataLoader\n",
    "功能：构建可迭代的数据装载器\n",
    "- dataset：Dataset类，决定数据从哪读取及如何读取\n",
    "- batchsize：批大小\n",
    "- num_works:是否多进程读取数据\n",
    "- shuffle：每个epoch是否乱序\n",
    "- drop_last: 当样本数不能被batchsize整除时，是否舍弃最后一批数据\n",
    "\n",
    "`Epoch:`所有训练样本都已输入到模型中，称为一个Epoch\\\n",
    "`Iteration:`一批样本输入到模型中，称为一个Iteration\\\n",
    "`Batchsizse:`批大小，决定一个Epoch有多少个Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd061f85-0b11-49ec-941c-8f8b07586384",
   "metadata": {},
   "source": [
    "### -torch.utils.data.Dataset\n",
    "功能：Dataset抽象类，所有自定义的Dataset需要继承它，并且复写\\\n",
    "\\_\\_getitem\\_\\_()\n",
    "\n",
    "```\n",
    "getitem:\n",
    "  接受一个索引，返回一个样本\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30b32f-4f66-43bf-ba25-285eafbf729f",
   "metadata": {},
   "source": [
    "$数据读取\\begin{cases}\n",
    "1. 读哪些数据?\\\\\n",
    "2. 从哪读数据?\\\\\n",
    "3. 怎么读数据?\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbc979-3f17-46eb-8385-f9185b632079",
   "metadata": {},
   "source": [
    "[Python标准库之os](https://blog.csdn.net/m0_46223009/article/details/128065092)\n",
    "#### os.walk() \n",
    "以root, dirs, files的方式树形遍历路径，并把root, dirs, files三元组返回\n",
    "\n",
    "$shutil模块\\begin{cases}\n",
    "1.复制文件或文件夹\\begin{cases}\n",
    "    1.1 shutil.copy(src, dst) \\rightarrow 复制文件\\\\\n",
    "    1.2 shutil.copytree(src, dst) \\rightarrow 复制文件夹\\\\\n",
    "    \\end{cases}\\\\\n",
    "2. 移动文件或文件夹 \\Rightarrow shutil.move(src, dst) \\rightarrow 移动文件或文件夹\\\\\n",
    "3. 删除文件夹（不能删除文件）\\Rightarrow shutil.rmtree(src) \\rightarrow 删除文件夹\\\\\n",
    "4. 创建和解压压缩包\\begin{cases}\n",
    "    4.1 zipobj.write() \\rightarrow 创建一个压缩包\\\\\n",
    "    4.2 zipobj.namelist() \\rightarrow 读取压缩包中的文件信息\\\\\n",
    "    4.3 zipobj.extract() \\rightarrow 将压缩包的单个文件，解压出来\\\\\n",
    "    4.4 zipobj.extractall() \\rightarrow 将压缩包中的所有文件解压出来\n",
    "    \\end{cases}\n",
    "\\end{cases}$\n",
    "\n",
    "---\n",
    "#### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db95612-6f8c-4b56-b402-1f33c215f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 1, train: 80, valid: 10, test: 10\n",
      "class: 100, train: 80, valid: 10, test: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def mkdir(new_dir):\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir) #可以递归创建多级目录\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "# 读哪的数据\n",
    "dataset_dir = os.path.join(root_dir, \"data\", \"RMB_data\")\n",
    "split_dir = os.path.join(root_dir, \"data\", \"rmb_split\")\n",
    "train_dir = os.path.join(split_dir, \"train\")\n",
    "valid_dir = os.path.join(split_dir, \"valid\")\n",
    "test_dir = os.path.join(split_dir, \"test\")\n",
    "\n",
    "\n",
    "train_pct = 0.8\n",
    "valid_pct = 0.1\n",
    "test_pct = 0.1\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for sub_dir in dirs:\n",
    "        imgs = os.listdir(os.path.join(root, sub_dir)) #listdir遍历文件夹所有文件并返回对应列表\n",
    "        imgs = list(filter(lambda x: x.endswith('.jpg'), imgs))\n",
    "        random.shuffle(imgs)\n",
    "        img_count = len(imgs)\n",
    "\n",
    "        # 前面已经打乱，之后枚举将每个文件放入对应文件夹几个\n",
    "        train_point = int(img_count * train_pct)\n",
    "        train_valid_point = int(img_count * (train_pct + valid_pct))\n",
    "\n",
    "        # 判断放入哪个文件夹\n",
    "        for i in range(img_count):\n",
    "            if i <= train_point:\n",
    "                out_dir = os.path.join(train_dir, sub_dir)\n",
    "            elif i <= train_valid_point:\n",
    "                out_dir = os.path.join(valid_dir, sub_dir)\n",
    "            else:\n",
    "                out_dir = os.path.join(test_dir, sub_dir)\n",
    "\n",
    "            # 文件夹不存在则创建\n",
    "            mkdir(out_dir)\n",
    "            # 找出对应文件\n",
    "            src_path = os.path.join(dataset_dir, sub_dir, imgs[i])\n",
    "            target_path = os.path.join(out_dir, imgs[i])\n",
    "\n",
    "            shutil.copy(src_path, target_path)\n",
    "\n",
    "        print(\"class: {}, train: {}, valid: {}, test: {}\".format(sub_dir, train_point, train_valid_point - train_point, img_count - train_valid_point))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ba95f-c57c-4a94-bd3b-ff8cbf12376b",
   "metadata": {},
   "source": [
    "---\n",
    "#### 数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635d717c-80f8-489b-bd97-a1f507ccaa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义DataLoader类\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "label_name = {\"1\":0, \"100\": 1}\n",
    "\n",
    "class RMBDataset(Dataset):\n",
    "    # 构造Dataset主要要写的构造函数\n",
    "    def __init__(self, data_dir, transform = None): \n",
    "        '''\n",
    "        rmb面额分类任务Dataset\n",
    "        :param data_dir：str, 数据集所在路径\n",
    "        :param transform: torch.transform, 数据预处理\n",
    "        '''\n",
    "        self.label_name = {\"1\": 0, \"100\": 1}\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    # 主要要写的，接受一个索引返回一个样本, 需要转换成RGB后的图片和标签\n",
    "    def __getitem__(self, index): \n",
    "        path_img, label = self.data_info[index]\n",
    "        img = Image.open(path_img).convert('RGB') # 0~255\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_img_info(data_dir):\n",
    "        data_info = list()\n",
    "        for root, dirs, _ in os.walk(data_dir):\n",
    "            #遍历类别\n",
    "            for sub_dir in dirs:\n",
    "                img_names = os.listdir(os.path.join(root, sub_dir))\n",
    "                img_names = list(filter(lambda x: x.endswith(\".jpg\"), img_names))\n",
    "\n",
    "                #遍历图片\n",
    "                for i in range(len(img_names)):\n",
    "                    img_name = img_names[i]\n",
    "                    path_img = os.path.join(root, sub_dir, img_name)\n",
    "                    label = label_name[sub_dir]\n",
    "                    data_info.append((path_img, int(label)))\n",
    "                                     \n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1b0b3-c158-4141-a0f5-f85ae81709a6",
   "metadata": {},
   "source": [
    "---\n",
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b8995-d8b8-4c90-a317-896bcff0f49b",
   "metadata": {},
   "source": [
    "# 2 transforms\n",
    "## torchvision.transforms: 常见的图像预处理方法\n",
    "torchvision：计算机视觉工具包\n",
    "\n",
    "提供的常见图像预处理方法：\n",
    "- 数据中心化\n",
    "- 数据标准化\n",
    "- 缩放\n",
    "- 裁剪\n",
    "- 旋转\n",
    "- 翻转\n",
    "- 填充\n",
    "- 噪声添加\n",
    "- 灰度变换\n",
    "- 线性变换\n",
    "- 仿射变换\n",
    "- 亮度、饱和度及对比度变换\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89c243-b1f8-4001-845f-e7fe0c527d0f",
   "metadata": {},
   "source": [
    "### - transforms.Normalize\n",
    "功能：逐channel的对图像进行标准化，得到0均值1方差的标准正态分布\n",
    "output = (input - mean) / std\n",
    "- mean: 各通道的均值\n",
    "- std：各通道的标准差\n",
    "- inplace：是否原地操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993ee9d-f0ce-42b1-91dd-f05e4e3ffbed",
   "metadata": {},
   "source": [
    "数据增强：又称数据增广，数据扩增，它是对训练集进行变换，使训练集更丰富，从而让模型更具泛化能力\n",
    "\n",
    "---\n",
    "## 2.1 图像裁剪\n",
    "### - transforms.CenterCrop\n",
    "功能：从图像中心裁剪图片\n",
    "- size：所需裁剪图片尺寸\n",
    "\n",
    "### - transforms.RandomCrop\n",
    "功能：从图片中随机裁剪出尺寸为size的图片\n",
    "- size：所需裁剪图片尺寸\n",
    "- padding：设置填充大小\n",
    "    - 当为a时，上下左右均填充a个像素\n",
    "    - 当为(a, b)时，上下填充b个像素，左右填充a个像素\n",
    "    - 当为(a, b, c, d)时，左上右下分别填充a, b, c, d\n",
    "- pad_if_need: 若图像小于设定size，则填充\n",
    "- padding_mode:填充模式，有4中模式\n",
    "    1. constant:像素值有fill设定\n",
    "    2. edge：像素值由图像边缘决定\n",
    "    3. reflect：镜像填充，最后一个像素不镜像，eg: [1, 2, 3, 4] --> [3, 2, 1, 2, 3, 4, 3, 2]\n",
    "    4. symmetric: 镜像填充，最后一个像素镜像，eg: [1, 2, 3, 4] --> [2, 1, 1, 2, 3, 4, 4, 3]\n",
    "- fill: constant时，设置填充的像素值\n",
    "\n",
    "### - RandomResizedCrop\n",
    "功能：随机大小、长宽比裁剪图片\n",
    "- size：所需裁剪图片尺寸\n",
    "- scale：随机裁剪面积比例，默认(0.08, 1)\n",
    "- ratio: 随机长宽比，默认(3/4, 4/3)\n",
    "- interpolation: 插值方法\n",
    "    - PIL.Image.NEAREST 最紧邻方法\n",
    "    - PIL.Image.BILNEAR 双线性插值\n",
    "    - PIL.Image.BICUBIC\n",
    "\n",
    "### - FiveCrop\n",
    "功能：在图像的上下左右以及中心裁剪出尺寸为size的5张图片\\\n",
    "但是返回的元祖形式，不能直接使用\n",
    "\n",
    "### - TenCrop\n",
    "功能：在FiveCrop的基础上，对这5张图片进行平行或者垂直镜像获得10张图片\n",
    "- size: 所需裁剪图片尺寸\n",
    "- vertical_flip: 是否垂直翻转\\\n",
    "返回的是元祖形式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1de628-2c99-4aa2-9634-81b0adde0ef6",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 图像翻转\n",
    "### - RandomHorizontalFlip\n",
    "### - RandomVerticalFlip\n",
    "功能：依概率水平（左右）或垂直（上下）翻转图片\n",
    "- p: 翻转概率\n",
    "\n",
    "### - Randomrotation\n",
    "功能：随机旋转图片\n",
    "\n",
    "- degrees: 旋转角度\n",
    "  - 当为a时，在(-a, a)之间选择旋转角度\n",
    "  - 当为(a, b)时， 在(a, b)之间选择旋转角度\n",
    "- resample: 重采样方法\n",
    "- expand：是否扩大图片，以保持原图信息\n",
    "- center: 旋转点设置，默认中心旋转"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9407fc9-bff1-4355-b17c-fc25b91aca73",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 其他方法\n",
    "### - Pad\n",
    "功能：对图片边缘进行填充\n",
    "- padding: 设置填充大小\n",
    "    - 当为a时，左上右下均填充a各像素\n",
    "    - 当为(a, b)时，上下填充b各像素，左右填充a各像素\n",
    "    - 当为(a, b, c, d)时，左，上，右，下分别填充a, b, c, d\n",
    "- padding_mode: 填充模式，有4种模式，constant, edge、reflect和symmetric\n",
    "- fill: 当为constant时，设置填充用的像素值\n",
    "\n",
    "### - ColorJitter\n",
    "功能：调整亮度、对比度、饱和度和色相\n",
    "- brightness:亮度调整因子\n",
    "    - 当为a时，从[max(0, 1 - a), 1 + a]中随机选择\n",
    "    - 当为(a, b)时，从[a, b]中\n",
    "- contrast：对比度参数，同brightness\n",
    "- saturation：饱和度参数，同brightness\n",
    "- hue：色相参数\n",
    "    - 当为a时，从[-a, a]中选择参数，注：$0\\leq a \\leq 0.5$\n",
    "    - 当为(a, b)时，从[a, b]中选择参数，注：$-0.5 \\leq a \\leq b \\leq 0.5$\n",
    "\n",
    "### - Crayscale\n",
    "### - RandomGrayscale\n",
    "功能：依概率将图片转换为灰度图\n",
    "- num_output_channels:输出通道数只能设1或3\n",
    "- p: 概率值，图像被转换为灰度图的概率\n",
    "\n",
    "### - RandomAffine\n",
    "功能：对图像进行放射变换，仿射变换是二维的线性变换，有五种基本原子变换构成，分别是旋转、平移、缩放、错切和翻转\n",
    "- degrees:旋转角度设置\n",
    "- translate：平移区间设置，如(a, b), a设置宽(width), b设置高(height)\n",
    "    图像在宽维度平移的区间为 $-img_width * a < dx < img_width * a$\n",
    "- scale: 缩放比例（以面积为单位）\n",
    "- fill: 填充颜色设置\n",
    "- shear:错切角度设置，有水平错切和垂直错切\n",
    "    - 若为a，则仅在x轴错切，错切角度在(-a, a)之间\n",
    "    - 若为(a, b)，则a设置x轴角度，b设置y的角度\n",
    "    - 若为(a, b, c, d), 则a, b设置x轴角度，c, d设置y轴角度\n",
    "- resample: 重采样方式，有NEAREST、BILINEAR、BICUBIC\n",
    "\n",
    "### - RandomErasing\n",
    "功能：对图像进行随机遮挡\\\n",
    "`注意`：接收值是张量，需要先转换成张量\n",
    "- p: 概率值，执行该操作的概率\n",
    "- scale: 遮挡区域的面积\n",
    "- ratio：遮挡区域长宽比\n",
    "- value：设置遮挡区域的像素值，(R, G, B) or (Gray)\n",
    "\n",
    "### - Lambda\n",
    "功能：用户自定义lambda方法\n",
    "- lambd: lambda匿名函数\n",
    "    lambda [arg1 [, arg2 ...]]: expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baba37b-5750-462c-abf7-c1bd24f5aa11",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 transforms的选择方法\n",
    "### - transforms.RandomChoice\n",
    "功能：从一系列transforms方法中随机挑选一个\n",
    "```\n",
    "transforms.RandomChoice([transforms1, transforms2, transforms3])\n",
    "```\n",
    "\n",
    "### - transforms.RandomApply\n",
    "功能：依据概率执行一组transforms操作\n",
    "```\n",
    "transforms.RandomApply([transforms1, transforms2, transforms3], p = 0.5)\n",
    "```\n",
    "\n",
    "### - transforms.RandomOrder\n",
    "功能：对一组transforms操作打乱顺序\n",
    "```\n",
    "transforms.RandomOrder([transforms1, transforms2, transforms3])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46de76d-4a04-4982-bea6-ccc5e82c87fd",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.5 自定义transforms方法\n",
    "自定义transforms要素：\n",
    "1. 仅接收一个参数，返回一个参数\n",
    "2. 注意上下游的输出与输入\n",
    "\n",
    "基本结构：\n",
    "```\n",
    "class YourTransforms(object):\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "    def __call__(self, img):\n",
    "        ...\n",
    "        return img\n",
    "```\n",
    "### 数据增强策略\n",
    "原则：让训练集与测试集更接近\n",
    "- 空间位置：平移\n",
    "- 色彩：灰度图，彩色抖动\n",
    "- 形状：放射变换\n",
    "- 上下文场景：遮挡，填充\n",
    "-  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ab7f4c-3da8-463f-89bd-37f47df395ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：自定义椒盐噪声\n",
    "'''\n",
    "椒盐噪声：又称脉冲噪声，是一种随机出现的白点或黑点，白点成为盐噪声，黑色成为椒噪声\n",
    "信噪比(SNR)是衡量噪声的比例，图像中为图像像素的占比\n",
    "'''\n",
    "class AddPepperNoise(object):\n",
    "    def __init__(self, snr, p = 0.9):\n",
    "        self.snr = snr\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        if random.uniform(0, 1) < self.p:\n",
    "            img_ = np.array(img).copy()\n",
    "            h, w, c = img_.shape\n",
    "            signal_pct = self.snr\n",
    "            noise_pct = (1 - self.snr)\n",
    "            mask = np.random.choice((0, 1, 2), size = (h, w, 1), p = [signal_pct, noise_pct / 2., noise_pct / 2.])\n",
    "            mask = np.repeat(mask, c, axis = 2)\n",
    "            img_[mask == 1] = 255 # 盐噪声\n",
    "            img_[mask == 2] = 0 # 椒噪声\n",
    "            return Image.fromarray(img_.astype('uint8')).convert('RGB')\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ddd38c-7133-40a4-94ef-26cb01ae2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_invert (img_, transform_train):\n",
    "    '''\n",
    "    将data进行反transform操作\n",
    "    :param img_: tensor\n",
    "    :param transform_train: torchvision.transforms\n",
    "    :return PIL image\n",
    "    '''\n",
    "    if 'Normalize' in str(transform_train):\n",
    "        norm_transform = list(filter(lambda x: isinstance(x, transforms.Normalize), transform_train.transforms))\n",
    "        mean = torch.tensor(norm_transform[0].mean, dtype = img_.dtype, device = img_.device)\n",
    "        std = torch.tensor(norm_transform[0].std, dtype = img_.dtype, device = img_.device)\n",
    "        img_.mul_(std[:, None, None]).add_(mean[:, None, None])\n",
    "\n",
    "    img_ = img_.transpose(0, 2).transpose(0, 1) #通道变换， 将C*H*W --> H*W*C\n",
    "    img_ = np.array(img_) * 255\n",
    "\n",
    "    if img_.shape[2] == 3: # 通道数为3表示为RGB图像\n",
    "        img_ = Image.fromarray(img_.astype('uint8')).convert('RGB')\n",
    "    elif img_.shape[2] == 1:# 通道数为1表示灰度图像\n",
    "        img_ = Image.fromarray(img_.astype('uint8').squeeze())\n",
    "    else:\n",
    "        raise Exception(\"Invalid img shape, expected 1 or 3 in axis 2, but got{}!\".format(img_.shape[2]))\n",
    "\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5df3730-6a76-48ea-9b2b-9a5807f6e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "def set_seed(seed = 1):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((32, 32)),  # 将图像缩放到 (32 x 32)大小\n",
    "    transforms.RandomCrop(32, padding = 4), # 对图像进行随机裁剪\n",
    "\n",
    "    \n",
    "    #--------测试transform各种数据增强---------#\n",
    "    # transforms.Resize((224, 224)),\n",
    "\n",
    "    # 裁剪\n",
    "    # 1 CenterCrop\n",
    "    # transforms.CenterCrop(512),\n",
    "\n",
    "    # 2 RandomCrop\n",
    "    # transforms.RandomCrop(224, padding = 16),\n",
    "    # transforms.RandomCrop(224, padding = (16, 64)),\n",
    "    # transforms.RandomCrop(224, padding = 16, fill = (255, 0, 0)),\n",
    "    # transforms.RandomCrop(512, pad_if_needed = True),\n",
    "    # transforms.RandomCrop(224, padding = 64, padding_mode = 'edge'), # 采用图像边界值进行填充\n",
    "    # transforms.RandomCrop(224, padding = 64, padding_mode = 'reflect'),\n",
    "    # transforms.RandomCrop(224, padding = 64, padding_mode = 'symmetric'), \n",
    "\n",
    "    # 3 RandomResizedCrop\n",
    "    # transforms.RandomResizedCrop(size = 224, scale = (0.08, 1)),\n",
    "\n",
    "    # 4 FiveCrop\n",
    "    # transforms.FiveCrop(112),\n",
    "    # transforms.Lambda(lambda crops: torch.stack([(transforms.ToTensor()(crop)) for crop in crops])), # 已经转换成张量，后续不需要转换了\n",
    "\n",
    "    # 5 TenCrop\n",
    "    # transforms.TenCrop(112, vertical_flip = True),\n",
    "    # transforms.Lambda(lambda crops: torch.stack([(transforms.ToTensor()(crop)) for crop in crops])),\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # 旋转\n",
    "    # 1 HorizontalFlip\n",
    "    # transforms.RandomHorizontalFlip(p = 0.5),\n",
    "\n",
    "    # 2 VerticalFlip\n",
    "    # transforms.RandomVerticalFlip(p = 0.5),\n",
    "\n",
    "    # 3 RandomRotation\n",
    "    # transforms.RandomRotation(90), #(-90, 90)\n",
    "    # transforms.RandomRotation((90), expand = True), #expand之后每张图片的尺寸不相同，将不能拼接 解决办法：1，batchsize改成1(不推荐) 2，在Resize\n",
    "    # transforms.Resize((224, 224)),\n",
    "\n",
    "    # transforms.RandomRotation(30, center = (0, 0)),\n",
    "    # transforms.RandomRotation(30, center = (0, 0), expand = True), #expand是根据中心旋转计算丢失的信息的，当不适用中心旋转仍然可能出现信息丢失\n",
    "    # transforms.Resize((224, 224)),\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # 其他\n",
    "    # 1 ColorJitter\n",
    "    # transforms.ColorJitter(brightness = 0.5),\n",
    "    # transforms.ColorJitter(contrast = 0.5),\n",
    "    # transforms.ColorJitter(saturation = 0.5),\n",
    "    # transforms.ColorJitter(hue = 0.3),\n",
    "\n",
    "    # 2 Grayscale\n",
    "    # transforms.Grayscale(num_output_channels = 3), # 需要彩色图像需要将通道数改为3\n",
    "    \n",
    "    # 3 Affine\n",
    "    # transforms.RandomAffine(degrees = 0, translate = (0.2, 0.2), fill = (255, 0, 0)), #必须要设置degrees参数\n",
    "    # transforms.RandomAffine(degrees = 0, scale = (0.7, 0.7)),\n",
    "    # transforms.RandomAffine(degrees = 0, shear = (0, 0, 0, 45)), # 在y轴错切\n",
    "    # transforms.RandomAffine(degrees = 0, shear = 90, fill = (255, 0, 0)), \n",
    "\n",
    "    # 4 Erasing\n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.RandomErasing(p = 1, scale = (0.02, 0.33), ratio = (0.5, 1), value = (254 / 255, 0, 0)),\n",
    "    # transforms.RandomErasing(p = 1, scale = (0.02, 0.33), ratio = (0.5, 1), value = 'random'),\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # transforms选择\n",
    "    # 1 RandomChoice\n",
    "    # transforms.RandomChoice([transforms.RandomHorizontalFlip(p = 0.5), transforms.RandomVerticalFlip(p = 0.5)]),\n",
    "\n",
    "    # 2 RandomApply\n",
    "    # transforms.RandomApply([transforms.RandomAffine(degrees = 0, shear = 90, fill = (255, 0, 0)),\n",
    "                           # transforms.Grayscale(num_output_channels = 3)], p = 0.5),\n",
    "\n",
    "    # 3 RandomOrder\n",
    "    # transforms.RandomOrder([transforms.RandomRotation(90),\n",
    "    #                        transforms.Pad(padding = 32),\n",
    "    #                        transforms.RandomAffine(degrees = 0, translate = (0.01, 0.1), scale = (0.9, 1.1))]),\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # 自定义transforms\n",
    "    # AddPepperNoise(0.9, p = 0.5),\n",
    "    # 使用transforms必须转换成张量\n",
    "    transforms.ToTensor(),  # 将图像转换成张量，同时对像素值进行归一化，从0~255 -> 0~1\n",
    "    transforms.Normalize(norm_mean, norm_std), # 数据标准化\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data = RMBDataset(data_dir = train_dir, transform = train_transform)\n",
    "valid_data = RMBDataset(data_dir = valid_dir, transform = valid_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ccb8a-9e6d-4ae2-b20c-cf7c7f94dc40",
   "metadata": {},
   "source": [
    "---\n",
    "# 3 模型\n",
    "## 3.1 网络模型的创建步骤\n",
    "$模型nn.Module\\begin{cases}\n",
    "模型创建\\begin{cases}\n",
    "构建网络层 \\rightarrow 卷积层，池化层，激活函数\\\\\n",
    "\\\\ \n",
    "拼接网络层 \\rightarrow LeNet, AlexNet, ResNet等\n",
    "\\end{cases}\\\\\n",
    "\\\\ \n",
    "权值初始化 \\rightarrow Xavier, Kaiming, 均匀分布, 正态分布\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$模型构建两要素\\begin{cases}\n",
    "构建子模块 \\rightarrow \\_\\_init\\_\\_()\\\\\n",
    "\\\\ \n",
    "拼接子模块 \\rightarrow forward()\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$torch.nn\\begin{cases}\n",
    "nn.Parameter \\rightarrow 张量子类，表示可学习参数，如weight，bias\\\\\n",
    "\\\\ \n",
    "nn.Module \\rightarrow 所有网络基类，管理网络属性\\\\\n",
    "\\\\ \n",
    "nn.functional \\rightarrow 函数具体实现，如卷积，池化，激活函数等\\\\\n",
    "\\\\ \n",
    "nn.init \\rightarrow 参数初始化方法\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "### - nn.Module\n",
    "- parameters: 存储管理nn.Parameter类\n",
    "- modules: 存储管理nn.Module类\n",
    "- buffers：存储管理缓冲属性，如BN层中的running_mean\n",
    "- ***_hooks: 存储管理钩子函数\n",
    "\n",
    "总结：\n",
    "- 一个module可以包含多个子module\n",
    "- 一个module相当于一个运算，必须实现forward()函数\n",
    "- 每个module都有8个字典管理它的属性\n",
    "\n",
    "## 3.2 容器\n",
    "$Containers\\begin{cases}\n",
    "nn.Sequetial \\rightarrow 按顺序包装多个网络层\\\\\n",
    "\\\\ \n",
    "nn.ModuleList \\rightarrow 像python的list一样包装多个网络层\\\\\n",
    "\\\\ \n",
    "nn.ModuleDict \\rightarrow 像python的dict一样包装多个网络层\\\\\n",
    "\\end{cases}$\n",
    "\n",
    "总结：\n",
    "nn.Sequential是nn.module的容器，用于按顺序包装一组网络层\\\n",
    "`各网络层之间严格按顺序执行，常用于block构建`\n",
    "- 顺序性：各网络层之间严格按照顺序构建\n",
    "- 自带forward(): 自带的forward里，通过for循环依次执行前向传播运算\n",
    "\n",
    "nn.ModuleList是nn.module的容器，用于包装一组网络层，以迭代方式调用网络层\\\n",
    "`常用于大量重复网络构建，通过for循环实现重复构建`\\\n",
    "主要方法：\n",
    "- append(): 在ModuleList后面添加网络层\n",
    "- extend(): 拼接两个ModuleList\n",
    "- insert(): 指定在ModuleList中位置插入网络层\n",
    "\n",
    "nn.ModuleDict是nn.module的容器，用于包装一组网络层，以索引方式调用网络层\\\n",
    "`常用于可选择的网络层`\\\n",
    "主要方法：\n",
    "- clear(): 清空ModuleDict\n",
    "- items(): 返回可迭代的键值对(key-value pairs)\n",
    "- keys(): 返回字典的建(key)\n",
    "- values(): 返回字典的值(value)\n",
    "- pop(): 返回一对键值，并从字典中删除\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea032b-9066-4135-8822-64682ba9ffe9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 具体模型\n",
    "### AlexNet\n",
    "AlexNet特点如下：\n",
    "1. 采用ReLU：替换饱和激活函数减轻梯度消失\n",
    "2. 采用LRN(Local Response Normalization): 对数据归一化，减轻梯度消失\n",
    "3. Dropout: 提高全连接层的鲁棒性，增加网络的泛化能力\n",
    "4. Data Augmentation: TenCrop, 色彩修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8cbb7-6bc4-43dd-be4a-e9b36903dd33",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.4 卷积层\n",
    "### - nn.Conv2d\n",
    "功能：对多个二维信号进行二维卷积\n",
    "主要参数：\n",
    "- in_channels: 输入通道数\n",
    "- out_channels: 输出通道数，等价于卷积核个数\n",
    "- kernel_size: 卷积核尺寸\n",
    "- stride: 步长\n",
    "- padding: 填充个数\n",
    "- dilation: 空洞卷积大小\n",
    "- groups：分组卷积设置\n",
    "- bias：偏置\\\n",
    "尺寸计算:\n",
    "$$out_{size} = \\dfrac{In_{size} + 2 \\times padding - kernel_{size}}{stride} + 1$$\n",
    "\n",
    "### 转置卷积\n",
    "用于对图像进行上采样\n",
    "### - nn.ConvTranspose2d\n",
    "功能：转置卷积实现上采样\n",
    "- in_channels: 输入通道数\n",
    "- out_channels：输出通道数\n",
    "- kernel_size: 卷积核尺寸\n",
    "- stride: 步长\n",
    "- padding: 填充个数\n",
    "- dilation: 空洞卷积大小\n",
    "- groups：分组卷积设置\n",
    "- bias：偏置\\\n",
    "尺寸计算：\n",
    "$$out_{size} = (in_{size} - 1) * stride - 2 \\times padding + kernel_{size}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f03451-fd08-48b6-9118-d1bcf59b089b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.5 池化、线性、激活函数层\n",
    "### 池化层\n",
    "池化运算：对信号进行收集并总结，类似水池收集水资源，因而得名池化层\\\n",
    "收集：多变少 总结：最大值/平均值\n",
    "### - nn.MaxPool2d\n",
    "功能：对二维信号(图像) 进行最大值池化\n",
    "- kernel_size: 池化核尺寸\n",
    "- stride: 步长\n",
    "- padding：填充个数\n",
    "- dilation: 池化核间隔大小\n",
    "- ceil_mode: 尺寸向上取整\n",
    "- return_indices: 记录池化像素索引\n",
    "\n",
    "### - nn.AvgPool2d\n",
    "功能：对二维信号(图像) 进行平均值池化\n",
    "- kernel_size: 池化核尺寸\n",
    "- stride: 步长\n",
    "- padding: 填充个数\n",
    "- ceil_mode: 尺寸向上取整\n",
    "- count_include_pad: 填充值用于计算\n",
    "- divisor_override: 除法因子\n",
    "\n",
    "### - nn.MaxUnpool2d\n",
    "功能：对二维信号（图像）进行最大值池化\\\n",
    "上采样\n",
    "- kernel_size: 池化核尺寸\n",
    "- stride：步长\n",
    "- padding: 填充个数\n",
    "\n",
    "### 线性层\n",
    "线性层：全连接层，其每个神经元与上一层所有神经元相连实现对前一层的线性组合，线性变换\n",
    "### - nn.Linear\n",
    "功能：对一维信号（向量）进行线性组合\n",
    "- in_features: 输入节点数\n",
    "- out_features: 输出节点数\n",
    "- bias: 是否需要偏置\\\n",
    "计算公式:\n",
    "$y = xW^T + bias$\n",
    "\n",
    "如果没有非线性层，那么根据矩阵运算的结合律，最后的结果仍是一层网络，而非线性层可以赋予对应深度的概念\n",
    "\n",
    "### - nn.Sigmoid\n",
    "计算公式：\\\n",
    "$y = \\frac{1}{1 + e^{-x}}$\\\n",
    "梯度公式：$y' = y * (1 - y)$\\\n",
    "特性：\n",
    "- 输出值在（0， 1），符合概率\n",
    "- 导数范围是[0, 0.25]，易导致梯度消失\n",
    "- 输出为非0均值，破坏数据分布\n",
    "\n",
    "### - nn.tanh\n",
    "计算公式:\\\n",
    "$ y = \\dfrac{sin x}{cos x} = \\dfrac{e^x - e^{-x}}{e^x + e^{-x}} = \\dfrac{2}{1 + e^{-2x}} + 1$\n",
    "梯度公式：\\\n",
    "$y' = 1 - y^2$\\\n",
    "特性：\n",
    "- 输出值在(-1, 1)，数据符合0均值\n",
    "- 导数范围是(0, 1), 易导致梯度消失\n",
    "\n",
    "### - nn.ReLU\n",
    "计算公式：\\\n",
    "$y = max(0, x)$\\\n",
    "梯度公式：\\\n",
    "$y' =\\begin{cases}\n",
    "1, x > 0\\\\\n",
    "undefined, x = 0\\\\\n",
    "0, x < 0\n",
    "\\end{cases}$\\\n",
    "特性：\n",
    "- 输出值均为正数，负半轴导致死神经元\n",
    "- 导数是1，缓解梯度消失，但易引发梯度爆炸\n",
    "\n",
    "### - nn.LeakyReLU\n",
    "- negative_slope: 负半轴斜率\n",
    "\n",
    "### - nn.PReLU\n",
    "- init: 可学习斜率\n",
    "\n",
    "### - nn.RReLU\n",
    "- lower: 均匀分布下限\n",
    "- upper：均匀分布上限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb157bf1-19e5-4808-adc6-f4191c12966a",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.6 权重初始化\n",
    "### 权重错误初始化将引发梯度消失和梯度爆炸\n",
    "如：\\\n",
    "$H_2 = H_1 * W_2$\\\n",
    "$\\Delta W_2 = \\dfrac{\\alpha Loss}{\\alpha W_2} = \\dfrac{\\alpha Loss}{\\alpha out} * \\dfrac{\\alpha out}{\\alpha H_2} * \\dfrac{H_2}{\\alpha w_2}$\\\n",
    "$=\\dfrac{\\alpha Loss}{\\alpha out} * \\dfrac{\\alpha out}{\\alpha H_2} * H_1$\\\n",
    "梯度消失：$H_1 \\rightarrow 0 \\Rightarrow \\Delta W_2 \\rightarrow 0$\\\n",
    "梯度爆炸: $H_1 \\rightarrow \\infty \\Rightarrow \\Delta W_2 \\rightarrow \\infty$\n",
    "\n",
    "当我们权值的方差设置为$\\dfrac{1}{n} \\Rightarrow std(W) = \\sqrt{\\dfrac{1}{n}}$时网络层输出的标准差都是1(n表示神经元个数) ， 当不含激活函数时\n",
    "\n",
    "当具有激活函数时：\n",
    "`方差一致性`：保持数据尺度维持在恰当范围，通常方差为1\\\n",
    "1. 激活函数：饱和函数，如Sigmoid, Tanh\\\n",
    "    需要满足的是\\\n",
    "    xavier\\\n",
    "    $D(W) = \\dfrac{2}{n_i + n_{i + 1}}$\n",
    "    而采用均匀分布时 W ~ U[-a, a]\\\n",
    "    $D(W) = \\dfrac{(-a -a)^2}{12} = \\dfrac{a^2}{3}$\\\n",
    "    得到W ~ U$[-\\dfrac{\\sqrt{6}}{\\sqrt{n_i + n_{i + 1}}}, \\dfrac{\\sqrt{6}}{\\sqrt{n_i + n_{i + 1}}}]$\n",
    "    \n",
    "3. 激活函数：ReLU及其变种\n",
    "    kaiming\n",
    "    $D(W) = \\dfrac{2}{n_i}$\\\n",
    "    对于其变种\\\n",
    "    $D(W) = \\dfrac{2}{(1 + a^2) * n_i}$(a表示负半轴斜率)\n",
    "\n",
    "### -- nn.init.calculate_gain\n",
    "功能：计算激活函数的方差变化尺度\n",
    "- nonlinearity：激活函数名称\n",
    "- param：激活函数的参数，如Leaky ReLU的negative_slop\n",
    "\n",
    "### - nn.init.xavier_uniform_(tensor, gain = 1)\n",
    "功能：Xavier均匀分布初始化权重\n",
    "\n",
    "### - nn.init.xavier_normal_(tensor, gain = 1)\n",
    "功能：Xavier正态分布初始化权重\n",
    "\n",
    "### - nn.init.kaiming_uniform_()\n",
    "功能：kaiming均匀初始化权重\n",
    "- tensor为权重tensor\n",
    "- a为激活函数负半轴斜率\n",
    "- mode：可选fan_in或fan_out， fan_in使正向传播时，方差一致；fan_out使反向传播时，方差一致\n",
    "- nonlinearity: 可选relu和leaky_relu， 默认为leaky_relu\n",
    "\n",
    "### - nn.init.kaiming_normal_()\n",
    "功能：kaiming正态分布初始化\n",
    "- a为激活函数负半轴斜率\n",
    "- mode可选fan_in 或fan_out, fan_in使正向传播时，方差一致；fan_out使反向传播时，方差一致\n",
    "- nonlinearity: 可选relu和leaky_relu， 默认为leaky_relu\n",
    "\n",
    "### - nn.init.uniform_(tensor, a = 0, b = 1)\n",
    "功能：使服从均匀分布U(a, b)\n",
    "\n",
    "### - nn.init.normal_(tensor, mean = 0, std = 1)\n",
    "功能：使服从正态分布N(mean, std)\n",
    "\n",
    "### - nn.init.canstan_(tensor, val)\n",
    "功能：使值为常数\n",
    "\n",
    "### - nn.init.eye_(tensor)\n",
    "功能：使值为单位矩阵\n",
    "\n",
    "### - nn.init.orthogonal_(tensor, gain = 1)\n",
    "功能：使tensor是正交的\n",
    "\n",
    "### - nn.init.sparse_(tensor, sparsity, std = 0.01)\n",
    "功能： 从正态分布N~(0, std)中进行稀疏化，使每一个column有一部分是0\n",
    "- sparsity：每一个column稀疏的比例，即为0的比例\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f2add-72bc-49b6-9e19-ad27bce790fa",
   "metadata": {},
   "source": [
    "---\n",
    "#### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02723404-efd9-467d-a319-d2c9a5cb0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        # self.features = nn.Sequential(\n",
    "        #     nn.Conv2d(3, 6, 5),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "        #     nn.Conv2d(6, 16, 5),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        # )\n",
    "\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(16*5*5, 120),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(120, 84),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(84, classes),\n",
    "        # )\n",
    "\n",
    "        # 有序字典，可以对网络层进行命名\n",
    "        self.features = nn.Sequential(OrderedDict({\n",
    "            'conv1': nn.Conv2d(3, 6, 5),\n",
    "            'relu1': nn.ReLU(),\n",
    "            'pool1': nn.MaxPool2d(kernel_size = 2, stride = 2), \n",
    "            'conv2': nn.Conv2d(6, 16, 5),\n",
    "            'relu2': nn.ReLU(),\n",
    "            'pool2': nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "        }))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict({\n",
    "            'fc1': nn.Linear(16*5*5, 120),\n",
    "            'relu3': nn.ReLU(),\n",
    "            'fc2': nn.Linear(120, 84),\n",
    "            'relu4': nn.ReLU(),\n",
    "            'fc3': nn.Linear(84, classes),\n",
    "        }))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, 0, 0.1)\n",
    "                m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc659af-1238-4d5b-9892-31a63fba1053",
   "metadata": {},
   "source": [
    "---\n",
    "# 4 损失函数\n",
    "损失函数：衡量模型输出与真实标签的差异\n",
    "$Loss = f(\\hat{y}, y)$\\\n",
    "代价函数：\\\n",
    "$Cost = \\dfrac{1}{N} \\sum\\limits^{N}_{i} f(\\hat{y_i}, y_i)$\\\n",
    "目标函数：\\\n",
    "$Obj = Cost + Regularization$\n",
    "\n",
    "### - nn.CrossEntropyLoss\n",
    "功能：nn.LogSoftmax()与nn.NLLLoss()结合，进行交叉熵计算\n",
    "- weight: 各类别的loss设置权值\n",
    "- ignore_index：忽略某个类别\n",
    "- reduction:计算模式，可为none/sum/mean\n",
    "none- 逐个元素计算\n",
    "sum- 所有元素求和，返回标量\n",
    "mean- 加权平均，返回标量\n",
    "\n",
    "### - nn.NLLLoss\n",
    "功能：实现负对数似然函数中的负号功能\n",
    "- weight: 各类别的loss设置权值\n",
    "- ignore_index: 忽略某个类别\n",
    "- reduction：计算模式，可为none/sum/mean\n",
    "\n",
    "### - BCELoss\n",
    "功能：二分类交叉熵\n",
    "`注意`：输入取值在[0, 1]\n",
    "- weight: 各类别的loss设置权值\n",
    "- ignore_index: 忽略某个类别\n",
    "- reduction: 计算模式，可为none/sum/mean\n",
    "\n",
    "### - nn.BCEWithLogitsLoss\n",
    "功能：结合Sigmoid与二分类交叉熵\n",
    "`注意：`网络最后不加sigmoid函数\n",
    "- pos_weight: 正样本权值\n",
    "- weight：各类别的loss设置权重\n",
    "- ignore_index：忽略某个类别\n",
    "- reduction:计算模式，可为none/sum/mean\n",
    "\n",
    "### - nn.L1Loss\n",
    "功能：计算inputs与target之差的绝对值\n",
    "\n",
    "### - nn.MSELoss\n",
    "功能：计算inputs与target之差的平方\n",
    "\n",
    "- reduction: 计算模式，可为none/sum/mean\n",
    "\n",
    "### - SmoothL1Loss\n",
    "功能：平滑的L1Loss\n",
    "计算公式:\\\n",
    "$loss(x, y) = \\dfrac{1}{n}\\sum\\limits_i z_i$\\\n",
    "$z_i \\begin{cases}\n",
    "0.5(x_i - y_i)^2, if|x_i - y_i| < 1\\\\\n",
    "\\\\ \n",
    "|x_i - y_i| - 0.5, otherwise\n",
    "\\end{cases}$\n",
    "- reduction\n",
    "\n",
    "<img src=\"https://p7.itc.cn/q_70/images03/20211213/3959b20ef2a84e8084c76f00fa7e92d5.jpeg\" style=\"width:400px; height: 300px\" />\n",
    "\n",
    "### - PoissonNLLLoss\n",
    "功能：泊松分布的负对数似然损失函数\n",
    "计算公式：\\\n",
    "$\\begin{cases}\n",
    "loss(input, target) = exp(input) - target*input, if log_input = True, \\\\\n",
    "\\\\ \n",
    "loss(input, target) = input - target * log(input + eps)\n",
    "\\end{cases}$\n",
    "- log_input: 输入是否为对数形式，决定计算公式\n",
    "- full: 计算所有loss，默认为false\n",
    "- eps：修正项，避免log(input) 为nan\n",
    "\n",
    "### - nn.KLDivLoss\n",
    "功能：计算KLD， KL散度，相对熵\\\n",
    "实际公式：\\\n",
    "$D_{KL}(P || Q) = \\sum\\limits_{i = 1}^{N} P(X_i) (log P(x_i) - logQ(x_i))$\\\n",
    "但是pytorch中实现方式是\\\n",
    "$l_n = y_n \\cdot (log y_n - x_n)$\\\n",
    "`注意`需提前将输入计算log-probabilities, 如通过nn.logsoftmax()\n",
    "- reduction: 多了一个batchmean\n",
    "- batchmean - batchsize维度求平均值\n",
    "\n",
    "### - nn.MarginRankingLoss\n",
    "功能：计算两个向量之间的相似度，用于排序任务\\\n",
    "计算公式：\\\n",
    "$loss(x, y) = max(0, -y \\times (x_1 - x_2) + margin)$\\\n",
    "`特别说明`: 该方法计算两组数据之间的差异，返回一个n*n的loss矩阵\n",
    "- margin: 边界值， $x_1$与$x_2$之间的差异值\n",
    "- reduction: 计算模式\n",
    "\n",
    "$\\begin{cases}\n",
    "y = 1时， 希望x_1 比 x_2大，当x_1 > x_2时，不产生loss\\\\\n",
    "\\\\ \n",
    "y = -1时，希望x_2比x_1大，当x_2 > x_1时，不产生loss\n",
    "\\end{cases}$\n",
    "\n",
    "### - nn.MultiLabelMarginLoss\n",
    "功能：多标签边界损失函数\\\n",
    "计算公式:\\\n",
    "$loss(x, y) = \\sum\\limits_{ij} \\dfrac{max(0, 1 - (x[y[j]] - x[i]))}{x.size(0)}$\\\n",
    "举例：四分类任务，样本x输入0类和3类\\\n",
    "标签：[0, 3, -1, -1], 不是~[1, 0, 0, 1]~\n",
    "- reduction：计算模式\n",
    "\n",
    "### - nn.SoftMarginLoss\n",
    "功能：计算二分类的logistic损失\\\n",
    "计算公式：\\\n",
    "$loss(x, y) = \\sum\\limits_{i} \\dfrac{log(1 + e^{-y[i] \\times x[i]})}{x.nelement()}$\n",
    "- reduction: 计算模式\n",
    "\n",
    "### - nn.MultiLabelSoftMarginLoss\n",
    "功能：SoftMarginLoss多标签版本\\\n",
    "计算公式:\\\n",
    "$loss(x, y) = - \\dfrac{1}{C} \\times \\sum\\limits_i y[i] \\times log(\\dfrac{1}{1 + e^{- x[i]}}) + (1 - y[i]) \\times log(\\dfrac{e^{-x[i]}}{1 + e^{-x[i]}})$\\\n",
    "C是标签数量\n",
    "- weight: 各类别的loss设置权值\n",
    "- reduction: 计算模式\n",
    "\n",
    "### - nn.MultiMarginLoss\n",
    "功能：计算多分类的折页损失\\\n",
    "计算公式：\\\n",
    "$loss(x, y) = \\dfrac{\\sum\\limits_i max(0, margin - x[y] + x[i])^p}{x.size(0)}$\n",
    "- p: 可选1或2\n",
    "- weight: 各类别的loss设置权值\n",
    "- margin：边界值\n",
    "- reduction：计算模式\n",
    "\n",
    "### - nn.TripletMarginLoss\n",
    "功能：计算三元组损失，人脸验证中常用\\\n",
    "计算公式：\\\n",
    "$L(a, p, n) = max{d(a_i, p_i) - d(a_i, n_i) + margin, 0}$\\\n",
    "$d(x_i, y_i) = || x_i - y_i||_p$\n",
    "- p: 范数的阶，默认为2\n",
    "- margin：边界值\n",
    "- reduction：计算模式\n",
    "\n",
    "### - nn.HingeEmbeddingLoss\n",
    "功能：计算两个输入的相似性，常用于非线性embedding和半监督学习\\\n",
    "计算公式:\\\n",
    "$l_n \\begin{cases}\n",
    "x_n, if y_n = 1, \\\\\n",
    "\\\\ \n",
    "max{0, \\Delta - x_n}, if y_n = -1\n",
    "\\end{cases}$\\\n",
    "`特别注意`：输入x应为两个输入之差的绝对值\\\n",
    "- margin:边界值\n",
    "- reduction：计算模式\n",
    "\n",
    "### - nn.CosineEmbeddingLoss\n",
    "功能：采用余弦相似度计算两个输入的相似度\\\n",
    "计算公式：\\\n",
    "$loss(x, y) =\\begin{cases}\n",
    "1 - cos(x_1, x_2), y = 1\\\\\n",
    "\\\\ \n",
    "max(0, cos(x_1, x_2) - margin), y = -1\n",
    "\\end{cases}$\\\n",
    "$cos(\\theta) = \\dfrac{A \\cdot B}{||A||||B||} = \\dfrac{\\sum\\limits_{i = 1}^{n} A_i \\times B_i}{\\sqrt{\\sum\\limits_{i = 1}^{n} (A_i)^2} \\times \\sqrt{\\sum\\limits_{i = 1}^{n} (B_i)^2}}$\n",
    "- margin: 可取值[-1, 1], 推荐[0, 0.5]\n",
    "- reduction: 计算模式\n",
    "\n",
    "### - nn.CTCLoss\n",
    "功能：计算CTC损失，解决时序类数据的分类Connectionist Temporal Classification\n",
    "- blank:blank label\n",
    "- zero_infinity: 无穷大的值或梯度置0\n",
    "- reduction：计算模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122d4d6-b9a6-480f-9690-c9b7ce293d53",
   "metadata": {},
   "source": [
    "---\n",
    "# 5 优化器Optimizer\n",
    "pytorch的优化器：管理并更新模型中可学习参数的值，使得模型输出更接近真实标签 \\\n",
    "class Optimizer的基本属性：\n",
    "- defaults: 优化器超参数\n",
    "- state: 参数的缓存，如momentum的缓存\n",
    "- param_groups:管理的参数组\n",
    "- _step_count:记录更新次数，学习率调整中使用\n",
    "基本方法：\n",
    "- zero_grad():清空所管理参数的梯度\n",
    "pytorch特性：张量梯度不自动清零\n",
    "- step(): 执行一步更新\n",
    "- add_param_group(): 添加参数组\n",
    "- state_dict(): 获取优化器当前状态信息字典\n",
    "- load_state_dict(): 加载状态信息字典 (可以断点继续训练)\n",
    "\n",
    "## 5.1 基本概念\n",
    "- Momentum(动量，冲量): 结合当前梯度与上一次更新信息，用于当前更新\\\n",
    "指数加权平均：$v_t = \\beta \\cdot v_{t- 1} + (1 - \\beta ) \\cdot \\theta_t$\\\n",
    "$\\beta$越小，记忆周期越短\n",
    "$\\begin{cases}\n",
    "梯度下降：w_{i + 1} = w_i - lr \\times g(w_i)\\\\ \n",
    "\\\\ \n",
    "pytorch中更新公式：\\begin{cases}\n",
    "v_i = m \\cdot v_{i - 1} + g(w_i)\\\\ \n",
    "\\\\ \n",
    "w_{i + 1} = w_i - lr \\cdot v_i\n",
    "\\end{cases}\n",
    "\\end{cases}$\\\n",
    "$w_{i + 1}$: 第i+1次更新的参数，lr: 学习率， $v_i$: 更新量， m: momentum系数，$g(w_i): w_i梯度$\n",
    "\n",
    "## 5.2 常用优化器\n",
    "### - optim.SGD\n",
    "- params: 管理的参数组\n",
    "- lr: 初始学习率\n",
    "- momentum:动量系数，贝塔\n",
    "- weight_decay: L2正则化系数\n",
    "- nesterov: 是否采用NAG\n",
    "\n",
    "### 其他\n",
    "1. optim.SGD: 随机梯度下降法\n",
    "2. optim.Adagrad: 自适应学习率梯度下降法\n",
    "3. optim.RMSprop: Adagrad的改进\n",
    "4. optim.Adadelta: Adagrad的改进\n",
    "5. optim.Adam: RMSprop结合Momentum\n",
    "6. optim.Adamax: Adam学习率上限\n",
    "7. optim.SparseAdam: 稀疏版的Adam\n",
    "8. optim. ASGD: 随机平均梯度下降\n",
    "9. optim.Rprop: 弹性反向传播\n",
    "10. optim.LBFGS: BFGS的改进\n",
    "\n",
    "## 5.3 学习率调整策略\n",
    "class _LRScheduler主要属性：\n",
    "- optimizer: 关联的优化器\n",
    "- last_epoch: 记录epoch数\n",
    "- base_lrs: 记录初始学习率\n",
    "主要方法：\n",
    "- step(): 更新下一个epoch的学习率\n",
    "- get_lr(): 虚函数，计算下一个epoch的学习率\n",
    "\n",
    "### MultiStepLR\n",
    "功能：按给定间隔调整学习率\n",
    "- milestones: 设定调整时刻数\n",
    "- gamma：调整系数\\\n",
    "调整方式：$lr = lr \\times gamma$\n",
    "\n",
    "### ExponentialLR\n",
    "optim.lr_scheduler.ExponentialLR()\\\n",
    "功能：按指数衰减调整学习率\n",
    "- gamma：指数底\\\n",
    "调整方式：$lr = lr \\times gamma^{epoch}$\n",
    "\n",
    "### CosineAnnealingLR\n",
    "功能：余弦周期调整学习率\n",
    "- T_max: 下降周期\n",
    "- eta_min: 学习率下限\\\n",
    "调整方式：$\\eta_t  = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta{min})(1 + cos(\\dfrac{T_{cur}}{T_{max}} \\pi))$\n",
    "\n",
    "### ReduceLRonPlateau\n",
    "功能：监控指标，当指控不再变化则调整\n",
    "- mode：min/max两种模式（不再下降/不再上升）\n",
    "- factor: 调整系数\n",
    "- patience: \"耐心\"，接受几次不变化\n",
    "- cooldown: \"冷却时间\"，停止监控一段时间\n",
    "- verbose: 是否打印日志\n",
    "- min_lr: 学习率下限\n",
    "- eps：学习率衰减最小值\n",
    "\n",
    "### LambdaLR\n",
    "功能：自定义调整策略\n",
    "- lr_lambda: function or list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48927d-2753-4bc0-be20-1dd563aca24e",
   "metadata": {},
   "source": [
    "--- \n",
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c659c77-4d59-4e44-a465-413aec592b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:Epoch[000/010] Iteration[010/011] Loss: 0.6705 Acc:60.62%\n",
      "Valid:\t Epoch[000/010] Iteration[002/002] Loss: 0.8432 Acc:100.00%\n",
      "Training:Epoch[001/010] Iteration[010/011] Loss: 0.3099 Acc:96.25%\n",
      "Valid:\t Epoch[001/010] Iteration[002/002] Loss: 0.5155 Acc:80.00%\n",
      "Training:Epoch[002/010] Iteration[010/011] Loss: 0.1072 Acc:95.62%\n",
      "Valid:\t Epoch[002/010] Iteration[002/002] Loss: 0.0003 Acc:100.00%\n",
      "Training:Epoch[003/010] Iteration[010/011] Loss: 0.0088 Acc:99.38%\n",
      "Valid:\t Epoch[003/010] Iteration[002/002] Loss: 0.0003 Acc:100.00%\n",
      "Training:Epoch[004/010] Iteration[010/011] Loss: 0.0674 Acc:98.12%\n",
      "Valid:\t Epoch[004/010] Iteration[002/002] Loss: 0.0018 Acc:100.00%\n",
      "Training:Epoch[005/010] Iteration[010/011] Loss: 0.1751 Acc:96.25%\n",
      "Valid:\t Epoch[005/010] Iteration[002/002] Loss: 0.0070 Acc:100.00%\n",
      "Training:Epoch[006/010] Iteration[010/011] Loss: 0.0072 Acc:99.38%\n",
      "Valid:\t Epoch[006/010] Iteration[002/002] Loss: 0.0000 Acc:100.00%\n",
      "Training:Epoch[007/010] Iteration[010/011] Loss: 0.2251 Acc:97.50%\n",
      "Valid:\t Epoch[007/010] Iteration[002/002] Loss: 0.0016 Acc:100.00%\n",
      "Training:Epoch[008/010] Iteration[010/011] Loss: 1.5283 Acc:86.88%\n",
      "Valid:\t Epoch[008/010] Iteration[002/002] Loss: 0.0058 Acc:100.00%\n",
      "Training:Epoch[009/010] Iteration[010/011] Loss: 0.0595 Acc:97.50%\n",
      "Valid:\t Epoch[009/010] Iteration[002/002] Loss: 0.0000 Acc:100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 超参数\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.01\n",
    "log_interval = 10 #日志打印间隔\n",
    "val_interval = 1\n",
    "\n",
    "# -------------------导入数据-------------------- #\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "valid_loader = DataLoader(dataset = valid_data, batch_size = BATCH_SIZE)\n",
    "\n",
    "# -------------------构建模型-------------------- #\n",
    "net = LeNet(classes = 2)\n",
    "net.initialize_weights()\n",
    "\n",
    "# -------------------损失函数-------------------- #\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------优化器---------------------- #\n",
    "optimizer = optim.SGD(net.parameters(), lr = LR, momentum = 0.9)  # 选择优化器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 10) # 设置学习率下降策略\n",
    "\n",
    "# -------------------训练----------------------- #\n",
    "train_curve = list()\n",
    "valid_curve = list()\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "\n",
    "    loss_mean = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        # forward\n",
    "        inputs, labels = data\n",
    "        \n",
    "        ##-----------------查看输入图片--------------------\n",
    "        # img_tensor = inputs[0, ...]\n",
    "        # img = transform_invert(img_tensor, train_transform)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        # plt.pause(0.5)\n",
    "        # plt.close()\n",
    "        # break\n",
    "\n",
    "        ### 查看FiveCrop的图片\n",
    "        # bs, ncrops, c, h, w = inputs.shape\n",
    "        # for n in range(ncrops):\n",
    "        #     img_tensor = inputs[0, n, ...]\n",
    "        #     img = transform_invert(img_tensor, train_transform)\n",
    "        #     plt.imshow(img)\n",
    "        #     plt.show()\n",
    "        #     plt.pause(0.5)\n",
    "        #     plt.close()\n",
    "        \n",
    "        ##---------------------------------------------------\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计分类情况\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().numpy()\n",
    "\n",
    "        # 打印训练信息\n",
    "        loss_mean += loss.item()\n",
    "        train_curve.append(loss.item())\n",
    "        if (i+1) % log_interval == 0:\n",
    "            loss_mean = loss_mean / log_interval\n",
    "            print(\"Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch, MAX_EPOCH, i+1, len(train_loader), loss_mean, correct / total))\n",
    "            loss_mean = 0.\n",
    "\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    # validate the model\n",
    "    if (epoch+1) % val_interval == 0:\n",
    "\n",
    "        correct_val = 0.\n",
    "        total_val = 0.\n",
    "        loss_val = 0.\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for j, data in enumerate(valid_loader):\n",
    "                inputs, labels = data\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).squeeze().sum().numpy()\n",
    "\n",
    "                loss_val += loss.item()\n",
    "\n",
    "            valid_curve.append(loss_val/valid_loader.__len__())\n",
    "            print(\"Valid:\\t Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch, MAX_EPOCH, j+1, len(valid_loader), loss_val, correct_val / total_val))\n",
    "\n",
    "train_x = range(len(train_curve))\n",
    "train_y = train_curve\n",
    "\n",
    "train_iters = len(train_loader)\n",
    "valid_x = np.arange(1, len(valid_curve) + 1) * train_iters * val_interval\n",
    "valid_y = valid_curve\n",
    "\n",
    "plt.plot(train_x, train_y, label = 'Train')\n",
    "plt.plot(valid_x, valid_y, label = 'Valid')\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
